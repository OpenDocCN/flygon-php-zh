- en: Chapter 2. Inserting, Updating, and Deleting Documents from Solr
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第2章。向Solr插入、更新和删除文档
- en: 'We will start this chapter by discussing the Solr schema. We will explore the
    default schema provided by Solr. Further, we will explore:'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将从讨论Solr模式开始这一章。我们将探索Solr提供的默认模式。此外，我们将探讨：
- en: Pushing sample data into Solr
  id: totrans-2
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将示例数据推送到Solr
- en: Adding sample documents to the Solr index
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将示例文档添加到Solr索引
- en: Using PHP to add documents to the Solr index
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用PHP向Solr索引添加文档
- en: Updating documents in Solr using PHP
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用PHP在Solr中更新文档
- en: Deleting documents in Solr using PHP
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用PHP在Solr中删除文档
- en: Using commit, rollback, and index optimization
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用提交、回滚和索引优化
- en: The Solr schema
  id: totrans-8
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Solr模式
- en: The Solr schema mostly consists of fields and field types. It defines the fields
    that are to be stored in the Solr index and the processing that should happen
    on data being indexed or searched in those fields. Internally, the schema is used
    to assign properties to the fields used for creating a document that is to be
    indexed using the Lucene API. The default schema available with Solr can be located
    in `<solr_home>/example/solr/collection1/conf/schema.xml`. Here, `collection1`
    is the name of the core.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: Solr模式主要由字段和字段类型组成。它定义了要存储在Solr索引中的字段以及在对这些字段进行索引或搜索时应该发生的处理。在内部，模式用于为使用Lucene
    API创建要进行索引的文档分配属性。Solr提供的默认模式可以在`<solr_home>/example/solr/collection1/conf/schema.xml`中找到。在这里，`collection1`是核心的名称。
- en: Note
  id: totrans-10
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: A Solr server can have multiple cores and each core can have its own schema.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: Solr服务器可以有多个核心，每个核心可以有自己的模式。
- en: Let us open up the `schema.xml` file and go through it. In the XML file, we
    can see that there is a section for fields inside which there are multiple fields.
    Also, there is another section for types. The types section contains different
    entries of `fieldType`, which define the type of field in terms of how the field
    will be processed during indexing and during query. Let us understand how to create
    a `fieldType` entry.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们打开`schema.xml`文件并仔细阅读。在XML文件中，我们可以看到有一个字段的部分，在其中有多个字段。另外，还有一个类型的部分。类型部分包含不同的`fieldType`条目，定义了字段的类型，以及在索引和查询期间如何处理字段。让我们了解如何创建`fieldType`条目。
- en: 'The `fieldType` entry consists of a name attribute that is used in field definitions.
    The class attribute defines the behavior of the `fieldType` entry. Some other
    attributes are:'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: '`fieldType`条目包括一个用于字段定义的名称属性。类属性定义了`fieldType`条目的行为。还有一些其他属性：'
- en: '`sortMissingLast`: If set to true this attribute will cause documents without
    the field to come after documents that have this field.'
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`sortMissingLast`：如果设置为true，此属性将导致没有该字段的文档出现在具有该字段的文档之后。'
- en: '`sortMissingFirst`: If set to true this attribute will cause documents without
    the field to come before documents that have this field.'
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`sortMissingFirst`：如果设置为true，此属性将导致没有该字段的文档出现在具有该字段的文档之前。'
- en: '`precisionStep`: Lower values of `precisionstep` means more precisions, more
    terms in the index, larger index, and faster range queries. `0` disables indexing
    at different precision levels.'
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`precisionStep`：`precisionstep`的较低值意味着更高的精度，索引中的更多术语，更大的索引和更快的范围查询。`0`禁用在不同精度级别进行索引。'
- en: '`positionIncrementGap`: It defines the positions between the last token of
    one entry and the first token of next entry in a multivalued field. Let us take
    an example.'
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`positionIncrementGap`：它定义了多值字段中一个条目的最后一个标记和下一个条目的第一个标记之间的位置。让我们举个例子。'
- en: Suppose there are two values in a multivalued field in a document. The first
    value is `aa bb` and the second value is `xx yy`. Ideally, the positions assigned
    to these tokens during indexing will be `0`, `1`, `2`, and `3` for tokens `aa`,
    `bb`, `xx`, and `yy` respectively.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 假设文档中的多值字段中有两个值。第一个值是`aa bb`，第二个值是`xx yy`。理想情况下，在索引期间分配给这些标记的位置将分别为`0`、`1`、`2`和`3`，对应于标记`aa`、`bb`、`xx`和`yy`。
- en: A search for `bb xx` will give this document in its result. To prevent this
    from happening, we have to give a large `positionIncrementGap` say `100`. Now
    the positions assigned to these tokens will be `0`, `1`, `100`, and `101` for
    tokens `aa`, `bb`, `xx`, and `yy`. A search for `bb xx` will not give results
    as `bb` and `xx` are not near to each other.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 搜索`bb xx`将在其结果中给出此文档。为了防止这种情况发生，我们必须给出一个较大的`positionIncrementGap`，比如`100`。现在，分配给这些标记的位置将分别为`0`、`1`、`100`和`101`，对应于标记`aa`、`bb`、`xx`和`yy`。搜索`bb
    xx`将不会给出结果，因为`bb`和`xx`不相邻。
- en: 'The `FieldType` entries are either primitive such as `String`, `Int`, `Boolean`,
    `Double`, `Float`, or a derived field type. A derived field type can contain analyzer
    sections for defining the processing that will happen during either indexing or
    query. Each analyzer section consists of a single **tokenizer** and multiple filters.
    They define how data is processed. For example, there is a `fieldType text_ws`
    where the **analyzer** is a `WhiteSpaceTokenizerFactory`. So any data being indexed
    or searched in a field of the `text_ws` type will have the data broken over white
    space into multiple tokens. Another `fieldType text_general` has separate analyzer
    entries for indexes and queries. During analysis for indexing the data is passed
    through a tokenizer known as `StandardTokenizerFactory` and then through multiple
    filters. Following are filters that we use:'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: '`FieldType`条目可以是原始的，如`String`、`Int`、`Boolean`、`Double`、`Float`，也可以是派生的字段类型。派生字段类型可以包含用于定义在索引或查询期间将发生的处理的分析器部分。每个分析器部分包含一个**分词器**和多个过滤器。它们定义了数据的处理方式。例如，有一个`fieldType
    text_ws`，其中**分析器**是`WhiteSpaceTokenizerFactory`。因此，在`text_ws`类型的字段中进行索引或搜索的任何数据都将在空格上被分割成多个标记。另一个`fieldType
    text_general`具有用于索引和查询的单独的分析器条目。在索引数据的分析过程中，数据通过一个称为`StandardTokenizerFactory`的分词器，然后通过多个过滤器。以下是我们使用的过滤器：'
- en: '`StopFilterFactory`: This filters are used for removal of stop words that are
    defined in `stopwords.txt`'
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`StopFilterFactory`：这些过滤器用于删除在`stopwords.txt`中定义的停用词'
- en: '`SynonymFilterFactory`: This filters are used for assigning synonyms to words
    that are defined in `index_synonyms.txt`'
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`SynonymFilterFactory`：这些过滤器用于为在`index_synonyms.txt`中定义的单词分配同义词'
- en: '`LowerCaseFilterFactory`: This filter is used for converting the text in all
    the tokens to lowercase'
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`LowerCaseFilterFactory`：此过滤器用于将所有标记中的文本转换为小写'
- en: Similarly, there are different analyses happening to the query on this field
    during search. And that is defined by the analyzer of the type query.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 同样，在搜索期间，对该字段的查询进行了不同的分析。这由类型查询的分析器定义。
- en: Most of the field types that are required are generally provided in the default
    schema. But we can go ahead and create a new field type if we feel a need for
    it.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 大多数所需的字段类型通常在默认模式中提供。但是，如果我们觉得有必要，我们可以继续创建新的字段类型。
- en: 'Each field consists of a name and a type, which are mandatory, and some other
    attributes. Let''s run through the attributes:'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 每个字段都包括名称和类型，这是必需的，还有一些其他属性。让我们来看看这些属性：
- en: '`name`: This attribute displays the name of the field.'
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`name`：此属性显示字段的名称。'
- en: '`type`: This attribute defines the type of the field. All types are defined
    as the `fieldType` entries we discussed before.'
  id: totrans-28
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`type`：此属性定义字段的类型。所有类型都定义为我们之前讨论的`fieldType`条目。'
- en: '`indexed` : This attribute is true if the data in this field has to be indexed.
    The text in indexed fields is broken into tokens and an index is created from
    the tokens, which can be used for searching the document based on these tokens.'
  id: totrans-29
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`indexed`：如果此字段中的数据需要被索引，则此属性为true。已索引字段中的文本被分解为标记，并从这些标记创建索引，可以根据这些标记搜索文档。'
- en: '`stored` : This attribute is true if the data in this field also needs to be
    stored. Data that has been indexed cannot be used to construct the original text.
    So text in fields are stored separately for retrieving original text of the document.'
  id: totrans-30
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`stored`：如果此字段中的数据也需要存储，则此属性为true。已索引的数据不能用于构建原始文本。因此，字段中的文本是单独存储的，以检索文档的原始文本。'
- en: '`multivalued` : This attribute is true if the field contains multiple values
    within a single document. An example of multiple values associated with a document
    is **tags**. A document can have multiple tags and for search on any of the tags,
    the same document has to be returned.'
  id: totrans-31
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`multivalued`：如果字段在单个文档中包含多个值，则此属性为true。**标签**就是文档关联的多个值的一个例子。一个文档可以有多个标签，对于任何标签的搜索，都必须返回相同的文档。'
- en: '`required` : This attribute is true if the field is mandatory to be populated
    for every document during index creation.'
  id: totrans-32
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`required`：如果字段在索引创建期间对每个文档都是必需的，则此属性为true。'
- en: In addition to normal fields, the schema consists of some dynamic fields, which
    add flexibility in defining the field's names. For example, a dynamic field by
    the name of `*_i` will match any field ending with `_i`, for example, `genre_i`
    or `xyz_i`.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 除了普通字段外，模式还包括一些动态字段，这些字段增加了定义字段名称的灵活性。例如，名为`*_i`的动态字段将匹配以`_i`结尾的任何字段，例如`genre_i`或`xyz_i`。
- en: 'Some other sections in the schema are:'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 模式中的其他部分有：
- en: '**uniqueKey**: This section defines a field to be unique and mandatory. This
    field will be used to enforce uniqueness among all documents.'
  id: totrans-35
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**uniqueKey**：此部分定义一个字段为唯一且必需的。此字段将用于在所有文档中强制执行唯一性。'
- en: '**copyField**: This section can be used to copy multiple fields into a single
    field. So we can have multiple text fields with different field types and a super
    field where all text fields are copied for a generic search among all fields.'
  id: totrans-36
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**copyField**：此部分可用于将多个字段复制到单个字段中。因此，我们可以有多个具有不同字段类型的文本字段，以及一个超级字段，其中所有文本字段都被复制，以便在所有字段中进行通用搜索。'
- en: Adding sample documents to the Solr index
  id: totrans-37
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 向Solr索引添加示例文档
- en: 'Let us push in some sample data into Solr. Go to `<solr_dir>/example/exampledocs`.
    Execute the following commands to add all sample documents into our Solr index:'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们将一些示例数据推送到Solr中。转到`<solr_dir>/example/exampledocs`。执行以下命令将所有示例文档添加到我们的Solr索引中：
- en: '[PRE0]'
  id: totrans-39
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'To check how many documents have been indexed go to the following URL:'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 要检查已索引多少文档，请转到以下网址：
- en: '[PRE1]'
  id: totrans-41
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: This is a query to Solr that asks to return all the documents in the index.
    The `numFound` field in the XML output specifies the number of documents in our
    Solr index.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个向Solr查询，要求返回索引中的所有文档。XML输出中的`numFound`字段指定了我们Solr索引中的文档数量。
- en: '![Adding sample documents to the Solr index](graphics/4920_02_01.jpg)'
  id: totrans-43
  prefs: []
  type: TYPE_IMG
  zh: '![将示例文档添加到Solr索引](graphics/4920_02_01.jpg)'
- en: 'We are working with the default schema. To check the schema, go to the following
    URL:'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 我们正在使用默认模式。要检查模式，请转到以下网址：
- en: '[PRE2]'
  id: totrans-45
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'The following screenshot shows the content of a sample schema file `schema.xml`:'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 以下截图显示了示例模式文件`schema.xml`的内容：
- en: '![Adding sample documents to the Solr index](graphics/4920_02_02.jpg)'
  id: totrans-47
  prefs: []
  type: TYPE_IMG
  zh: '![将示例文档添加到Solr索引](graphics/4920_02_02.jpg)'
- en: 'We can see that there are multiple fields: `id`, `title`, `subject`, `description`,
    `author`, and others. Configuring Solr is all about designing the schema to suit
    the field requirements. We can also see that the `id` field is unique.'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以看到有多个字段：`id`、`title`、`subject`、`description`、`author`等。配置Solr就是为了设计模式以满足字段的要求。我们还可以看到`id`字段是唯一的。
- en: 'We can insert documents in Solr via the `post.jar` program as seen earlier.
    To do this, we would need to create an XML, CSV, or JSON file specifying the fields
    and values in the document. Once the file is ready, we can simply call one of
    the earlier mentioned commands to insert the document in the file into Solr. The
    XML format for the file is as follows:'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以通过`post.jar`程序向Solr插入文档，就像之前看到的那样。为此，我们需要创建一个指定文档中字段和值的XML、CSV或JSON文件。一旦文件准备好，我们可以简单地调用前面提到的命令之一，将文件中的文档插入Solr。文件的XML格式如下：
- en: '[PRE3]'
  id: totrans-50
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: The `post.jar` file is a program for processing multiple documents in a file.
    We can use it if we have a large number of documents to insert and the documents
    are in a CSV, XML, or JSON format. The PHP code used to insert documents in Solr
    in turn creates a Solr URL and makes a `curl` call with appropriate data.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: '`post.jar`文件是用于处理文件中的多个文档的程序。如果我们有大量文档要插入，而且文档是以CSV、XML或JSON格式存在的，我们可以使用它。用于向Solr插入文档的PHP代码反过来创建一个Solr
    URL，并使用适当的数据进行`curl`调用。'
- en: '[PRE4]'
  id: totrans-52
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: Using PHP to add documents to the Solr index
  id: totrans-53
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用PHP向Solr索引添加文档
- en: 'Let us see the code to add documents to Solr using the Solarium library. When
    we execute the following query we can see that there are three books of the author
    *George R R Martin* in our Solr index:'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看使用Solarium库向Solr添加文档的代码。当我们执行以下查询时，我们可以看到在我们的Solr索引中有三本作者*George R R Martin*的书：
- en: '[PRE5]'
  id: totrans-55
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'Let us add the remaining two books, which have also been published to our index:'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们添加剩下的两本书，这些书也已经发布到我们的索引中：
- en: 'Create a solarium client using the following code:'
  id: totrans-57
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用以下代码创建一个solarium客户端：
- en: '[PRE6]'
  id: totrans-58
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'Create an instance of the update query using the following code:'
  id: totrans-59
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用以下代码创建更新查询的实例：
- en: '[PRE7]'
  id: totrans-60
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: Create the documents you want to add and add fields to the document.
  id: totrans-61
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建要添加的文档并向文档添加字段。
- en: '[PRE8]'
  id: totrans-62
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: Similarly, another document `$doc2` can be created.
  id: totrans-63
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 同样，可以创建另一个文档`$doc2`。
- en: Note
  id: totrans-64
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: Note that the `id` field is unique. So we will have to keep different `id` field
    for different documents that we add to Solr.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，`id`字段是唯一的。因此，我们必须为添加到Solr的不同文档保留不同的`id`字段。
- en: 'Add documents to the update query followed by the `commit` command:'
  id: totrans-66
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将文档添加到更新查询中，然后使用`commit`命令：
- en: '[PRE9]'
  id: totrans-67
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'Finally, execute the following query:'
  id: totrans-68
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后，执行以下查询：
- en: '[PRE10]'
  id: totrans-69
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'Let us execute the code using the following command:'
  id: totrans-70
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们使用以下命令执行代码：
- en: '[PRE11]'
  id: totrans-71
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: After executing the code, the search for martin gives five results
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 执行代码后，搜索马丁得到了五个结果
- en: 'To add a single document, we can call the `addDocument` function to the update
    query instance using the following line of code:'
  id: totrans-73
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 要添加单个文档，我们可以使用以下代码行将`addDocument`函数调用更新查询实例：
- en: '[PRE12]'
  id: totrans-74
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: Updating documents in Solr using PHP
  id: totrans-75
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用PHP更新Solr中的文档
- en: Let us see how we can use PHP code along with Solarium library to update documents
    in Solr.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看如何使用PHP代码以及Solarium库来更新Solr中的文档。
- en: First check if there are any documents with the word `smith` in our index.
  id: totrans-77
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 首先检查我们的索引中是否有任何包含`smith`这个词的文档。
- en: '[PRE13]'
  id: totrans-78
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: We can see `numFound=0`, which means that there are no such documents. Let us
    add a book to our index with the last name of the author as `smith`.
  id: totrans-79
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们可以看到`numFound=0`，这意味着没有这样的文档。让我们在我们的索引中添加一本作者姓氏为`smith`的书。
- en: '[PRE14]'
  id: totrans-80
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'If we run the same select query again, we can see that now there is one document
    in our index with the author as `Smith`. Let us now update the author''s name
    to `Jack Smith` and the price tag to `7.59`:'
  id: totrans-81
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如果我们再次运行相同的选择查询，我们可以看到现在我们的索引中有一个作者名为`Smith`的文档。现在让我们将作者的名字更新为`Jack Smith`，价格标签更新为`7.59`：
- en: '[PRE15]'
  id: totrans-82
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: On running the same query again, we can see that now the author name and price
    is updated in our index on Solr.
  id: totrans-83
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 再次运行相同的查询，我们可以看到现在在Solr的索引中作者姓名和价格已经更新。
- en: The process to update a document in Solr is similar to that of adding a document
    in Solr except for the fact that we have to set the `overwrite` flag to `true`.
    If no parameter is set, Solarium will not pass any flag to Solr. But on the Solr
    end, the `overwrite` flag is by default set to `true`. So any document to Solr
    will replace a previous document with the same unique key.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 更新Solr中的文档的过程与向Solr中添加文档的过程类似，只是我们必须将`overwrite`标志设置为`true`。如果没有设置参数，Solarium将不会向Solr传递任何标志。但在Solr端，`overwrite`标志默认设置为`true`。因此，向Solr添加任何文档都将替换具有相同唯一键的先前文档。
- en: Solr internally does not have an update command. In order to update a document,
    when we provide the unique key and the overwrite flag, Solr internally deletes
    and inserts the document again.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: Solr内部没有更新命令。为了更新文档，当我们提供唯一键和覆盖标志时，Solr内部会删除并再次插入文档。
- en: We will need to add all fields of the document again, even fields that are not
    required to be updated. Since Solr will be deleting the complete document and
    inserting the new document.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 我们需要再次添加文档的所有字段，即使不需要更新的字段也要添加。因为Solr将删除完整的文档并插入新文档。
- en: Another interesting parameter in the method signature is the commit within time.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 方法签名中的另一个有趣的参数是在时间内提交。
- en: '[PRE16]'
  id: totrans-88
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: The preceding code asks Solr to overwrite the document and commit within 10
    seconds. This is explained later in this chapter.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 上述代码要求Solr覆盖文档并在10秒内提交。这将在本章后面进行解释。
- en: We can also use the `addDocuments(array($doc1, $doc2))` command to update multiple
    documents in a single call.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还可以使用`addDocuments(array($doc1, $doc2))`命令一次更新多个文档。
- en: Deleting documents in Solr using PHP
  id: totrans-91
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用PHP在Solr中删除文档
- en: Now let us go ahead and delete this document from Solr.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们继续从Solr中删除这个文档。
- en: '[PRE17]'
  id: totrans-93
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'Now, if we run the following query on Solr, the document is not found:'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，如果我们在Solr上运行以下查询，将找不到文档：
- en: '[PRE18]'
  id: totrans-95
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: What we did here was that we created a query in Solr to search for all documents
    where the author field contains the `smith` word and then passed it as a delete
    query.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在这里做的是在Solr中创建一个查询，搜索作者字段包含`smith`单词的所有文档，然后将其作为删除查询传递。
- en: We can add multiple delete queries via the `addDeleteQueries` method. This can
    be used to delete multiple sets of documents in a single call.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以通过`addDeleteQueries`方法添加多个删除查询。这可以用于一次删除多组文档。
- en: '[PRE19]'
  id: totrans-98
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: When this query is executed, all documents where the author field is either
    `Burst` or `Alexander` are deleted from the index.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 执行此查询时，所有作者字段为`Burst`或`Alexander`的文档都将从索引中删除。
- en: In addition to deleting by a query, we can also delete by ID. Each book that
    we have added to our index has an `id` field, which we have marked as unique.
    To delete by ID, simply call the `addDeleteById($id)` function.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 除了通过查询删除，我们还可以通过ID删除。我们添加到索引的每本书都有一个`id`字段，我们将其标记为唯一。要按ID删除，只需调用`addDeleteById($id)`函数。
- en: '[PRE20]'
  id: totrans-101
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: We can also use the `addDeleteByIds(array $ids)` to delete multiple documents
    in a single go.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还可以使用`addDeleteByIds(array $ids)`一次删除多个文档。
- en: Note
  id: totrans-103
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: 'In addition to using PHP code to delete documents, we can also use `curl` calls
    to delete a document by ID or by query. The curl call to delete by ID is as follows:'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 除了使用PHP代码删除文档，我们还可以使用`curl`调用通过ID或查询删除文档。按ID删除的curl调用如下：
- en: '[PRE21]'
  id: totrans-105
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'And the `curl` call to delete by query is as follows:'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 通过查询删除的`curl`调用如下：
- en: '[PRE22]'
  id: totrans-107
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'Here is a simple way of deleting all documents from the Solr index:'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是从Solr索引中删除所有文档的简单方法：
- en: '[PRE23]'
  id: totrans-109
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: Commit, rollback, and index optimization
  id: totrans-110
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 提交、回滚和索引优化
- en: The `commitWithin` parameter that we have been passing as arguments to our `addDocument()`
    function specifies the time for the commit to happen for this add document operation.
    This leaves the control of when to do the commit to Solr itself. Solr optimizes
    the number of commits to a minimum while still fulfilling the update latency requirements.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 我们一直作为参数传递给`addDocument()`函数的`commitWithin`参数指定了此添加文档操作的提交时间。这将提交的控制权留给Solr本身。Solr会在满足更新延迟要求的同时将提交次数优化到最低。
- en: The rollback option is exposed via the `addRollback()` function. Rollback can
    be done since the last commit and before current commit. Once a commit has been
    done, the changes cannot be rolled back.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 回滚选项通过`addRollback()`函数公开。回滚可以在上次提交之后和当前提交之前进行。一旦提交完成，就无法回滚更改。
- en: '[PRE24]'
  id: totrans-113
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: Index optimization is one of the tasks that is not necessarily required. But
    an optimized index has better performance than a non-optimized index. To optimize
    an index using the PHP code, we can use the `addOptimize(boolean $softCommit,
    boolean $waitSearcher, int $maxSegments)` function. It has parameters to enable
    soft commit, wait until a new searcher is opened and number of segments to optimize
    to. Also note that index optimization slows down the execution of all other queries
    on Solr.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 索引优化并不一定是必需的任务。但是优化后的索引比未优化的索引性能更好。要使用PHP代码优化索引，我们可以使用`addOptimize(boolean $softCommit,
    boolean $waitSearcher, int $maxSegments)`函数。它具有启用软提交、等待新搜索器打开和优化段数的参数。还要注意，索引优化会减慢Solr上所有其他查询的执行速度。
- en: '[PRE25]'
  id: totrans-115
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: For more advanced options, we can also use the `addParam()` function to add
    key value pairs to the query string.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 对于更高级的选项，我们还可以使用`addParam()`函数向查询字符串添加键值对。
- en: '[PRE26]'
  id: totrans-117
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: It is generally advisable to combine multiple commands in a single request.
    The commands are executed in the order in which they are added to the request.
    But we should also take care not to build huge queries that exceed the limit of
    a request. Use rollbacks in exception scenarios to avoid partial updates/deletes
    when running bulk queries and perform commit separately.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 通常建议将多个命令组合在一个请求中。这些命令按照它们添加到请求中的顺序执行。但是我们也要注意不要构建超出请求限制的大型查询。在运行大量查询时，在异常情况下使用回滚来避免部分更新/删除，并单独执行提交。
- en: '[PRE27]'
  id: totrans-119
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: In the preceding piece of code if the `update` query throws an exception, then
    it is rolled back.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 在上述代码片段中，如果`update`查询抛出异常，那么它将被回滚。
- en: Summary
  id: totrans-121
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: In this chapter we started off by discussing the Solr schema. We got a basic
    understanding of how the Solr schema works. We then added some sample documents
    to our Solr index. Then we saw multiple pieces of code to add, update, and delete
    documents to our Solr index. We also saw how to use cURL to delete documents.
    We discussed how commit and rollback work on the Solr index. We also saw an example
    of how to use rollback in our code. We discussed index optimization using PHP
    code and the benefits of optimizing the Solr index.
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们首先讨论了Solr模式。我们对Solr模式的工作原理有了基本的了解。然后我们向Solr索引中添加了一些示例文档。然后我们看到了多个代码片段，用于向Solr索引添加、更新和删除文档。我们还看到了如何使用cURL删除文档。我们讨论了提交和回滚在Solr索引上的工作原理。我们还看到了如何在我们的代码中使用回滚的示例。我们讨论了使用PHP代码进行索引优化以及优化Solr索引的好处。
- en: In the next chapter we will see how to execute search queries on Solr using
    PHP code and explore different query modes available with Solr.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章中，我们将看到如何使用PHP代码在Solr上执行搜索查询，并探索Solr提供的不同查询模式。
