- en: Chapter 8. Advanced Solr – Grouping, the MoreLikeThis Query, and Distributed
    Search
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第8章。高级Solr-分组、MoreLikeThis查询和分布式搜索
- en: In this chapter we will look at some of the advanced concepts of Solr. We will
    look at grouping results based on certain criteria. We will also look at finding
    results similar to a particular document based on some terms within the document.
    We will explore distributed search that can be used to horizontally scale the
    Solr search infrastructure. Topics that will be covered in this chapter are
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将研究Solr的一些高级概念。我们将根据某些标准查看基于分组的结果。我们还将查找类似于特定文档的结果，这些结果基于文档内的某些术语。我们将探索分布式搜索，可用于水平扩展Solr搜索基础架构。本章将涵盖的主题包括
- en: Grouping results by field
  id: totrans-2
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 按字段分组的结果
- en: Grouping results by query
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 按查询分组的结果
- en: Running morelikethis query using PHP
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用PHP运行morelikethis查询
- en: Tuning parameters of morelikethis query
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 调整morelikethis查询的参数
- en: Distributed search
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 分布式搜索
- en: Setting up distributed search
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 设置分布式搜索
- en: Executing distributed search using PHP
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用PHP执行分布式搜索
- en: Setting up Solr master-slave
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 设置Solr主从
- en: Load balancing Solr queries using PHP
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用PHP进行Solr查询的负载平衡
- en: Grouping results by fields
  id: totrans-11
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 按字段分组的结果
- en: 'Result grouping is a feature where results are clubbed together based on certain
    criteria. Solr provides us grouping based on field or based on queries. Let us
    search for all books and group results based on author name and genre. Grouping
    should be done on non-tokenized fields as the grouping output makes more sense
    for the complete field value rather than individual tokens. The non-tokenized
    string fields for author name and genre are `author_s` and `genre_s`. Why? Remember
    we discussed a concept known as dynamic fields in [Chapter 2](ch02.html "Chapter 2. Inserting,
    Updating, and Deleting Documents from Solr"), *Inserting, Updating, and Deleting
    Documents from Solr*. The dynamic fields of type `*_s` is defined as `string`
    as shown in the following code, which is not tokenized in Solr:'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 结果分组是一种根据某些标准将结果合并在一起的功能。Solr根据字段或查询为我们提供分组。让我们搜索所有书籍，并根据作者姓名和流派对结果进行分组。应该在非标记化字段上进行分组，因为分组输出对于完整字段值而不是单个标记更有意义。作者姓名和流派的非标记化字符串字段分别为`author_s`和`genre_s`。为什么？记得我们在[第2章](ch02.html
    "第2章。向Solr插入、更新和删除文档")中讨论过一个概念，即动态字段，*向Solr插入、更新和删除文档*。类型为`*_s`的动态字段被定义为`string`，如下所示，它在Solr中没有标记化：
- en: '[PRE0]'
  id: totrans-13
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'We will have to get the grouping component and add the fields we need to group
    by as shown in the following query:'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将不得不获取分组组件，并添加我们需要按组分组的字段，如下查询所示：
- en: '[PRE1]'
  id: totrans-15
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'Let''s also set the number of items that Solr should return for each group
    with the following query:'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们还使用以下查询设置Solr应为每个组返回的项目数：
- en: '[PRE2]'
  id: totrans-17
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'And also return the total number of groups with the following query:'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 还可以使用以下查询返回组的总数：
- en: '[PRE3]'
  id: totrans-19
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'To display the grouping information we need to first get the grouping component
    from the result set with the following query:'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 显示分组信息，我们首先需要使用以下查询从结果集中获取分组组件：
- en: '[PRE4]'
  id: totrans-21
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'As we have done grouping on multiple fields we would be getting multiple groups
    in the result set. For each group in the groups array, we will get the number
    of matches and the number of group elements with the following code:'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 由于我们对多个字段进行了分组，因此在结果集中会得到多个分组。对于groups数组中的每个组，我们将使用以下代码获取匹配数和组元素数：
- en: '[PRE5]'
  id: totrans-23
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: We are iterating over the number of group elements to find the name/heading
    and number of elements in the group. And for each group element get the documents
    from that group element.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 我们正在迭代组元素的数量，以查找组中的名称/标题和元素数量。对于每个组元素，获取该组元素的文档。
- en: 'The query in the Solr query logs is as follows:'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: Solr查询日志中的查询如下：
- en: '[PRE6]'
  id: totrans-26
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'The parameters being passed are `group=true` to enable grouping and for each
    field we have a `group.field=<field_name>` parameter. The `group.limit` parameter
    is used to specify the number of documents to be retrieved for each group element.
    The output is as shown in the following screenshot:'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 传递的参数是`group=true`以启用分组，对于每个字段，我们有一个`group.field=<field_name>`参数。`group.limit`参数用于指定要检索的每个组元素的文档数。输出如下图所示：
- en: '![Grouping results by fields](graphics/4920OS_08_01.jpg)'
  id: totrans-28
  prefs: []
  type: TYPE_IMG
  zh: '![按字段对结果进行分组](graphics/4920OS_08_01.jpg)'
- en: Output of group by field.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 按字段分组的输出。
- en: Grouping results by queries
  id: totrans-30
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 按查询分组的结果
- en: 'Instead of grouping by a field, we can also group by query. Let us create groups
    for different price ranges. Instead of using the `addField()` function on the
    grouping component, we have to use the `addQuery()` function and specify our query
    as a parameter in the function as shown in the following:'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还可以按查询分组，而不是按字段分组。让我们为不同的价格范围创建组。在分组组件上不使用`addField()`函数，而是使用`addQuery()`函数，并在函数中指定我们的查询作为参数，如下所示：
- en: '[PRE7]'
  id: totrans-32
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: Here we have created 3 groups for price ranges $0 to $5, $5.01 to $10 and more
    than $10.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们为价格范围$0至$5、$5.01至$10和超过$10创建了3个组。
- en: 'We can also set sorting within a group using the `setSort()` function as shown
    in the following query:'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还可以使用`setSort()`函数在组内设置排序，如下查询所示：
- en: '[PRE8]'
  id: totrans-35
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'Code to display the groups is similar to that discussed earlier. Output from
    our code is shown in the following screenshot:'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 显示组的代码与之前讨论的类似。我们代码的输出如下图所示：
- en: '![Grouping results by queries](graphics/4920OS_08_02.jpg)'
  id: totrans-37
  prefs: []
  type: TYPE_IMG
  zh: '![通过查询对结果进行分组](graphics/4920OS_08_02.jpg)'
- en: From Solr logs we can see that instead of `group.field` parameter we have got
    multiple `group.query` parameters.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 从Solr日志中，我们可以看到我们得到了多个`group.query`参数，而不是`group.field`参数。
- en: '[PRE9]'
  id: totrans-39
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: Running more like this query using PHP
  id: totrans-40
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用PHP运行更多类似此查询
- en: '**More like this** feature of Solr can be used to construct a query based on
    the terms within a document. This feature helps us in retrieving documents similar
    to those in our query results. We have to specify the fields on which the more
    like this functionality is run. For efficiency purposes, it is recommended that
    we have `termVectors=true` for these fields. Let us understand how this functionality
    works by looking at an example. Suppose we want books that are similar to those
    appearing in the result. Similarity of books is derived from the author and the
    series to which they belong. So we would have to tell Solr to get books similar
    to the currently selected book based on the fields'' `author` and `series`. Solr
    (Lucene) internally compares all the tokens within the specified fields in all
    documents (books in our case) in the index with the fields of the currently selected
    book. And based on how many tokens are matching, it retrieves the results and
    ranks them so that the documents with maximum token matches are on top.'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: Solr的**更多类似此**功能可用于基于文档内部的术语构造查询。此功能帮助我们检索与我们查询结果中的文档类似的文档。我们必须指定运行更多类似此功能的字段。出于效率目的，建议我们为这些字段设置`termVectors=true`。让我们通过查看一个示例来了解此功能的工作原理。假设我们想要与结果中出现的书籍类似的书籍。书籍的相似性来自作者和它们所属的系列。因此，我们必须告诉Solr根据字段`author`和`series`获取与当前选择的书籍相似的书籍。Solr（Lucene）在索引中内部比较所选书籍的字段中的所有标记与所有文档（在我们的案例中是书籍）中指定字段的标记。根据匹配的标记数量，它检索结果并对其进行排名，以便具有最大标记匹配的文档排在前面。
- en: Let us add `termVectors=true` to our fields `author`&`*_t` (for `series_t`).
    Term vector is a collection of term frequency pairs optionally with positional
    information. Term vectors are basic building blocks for a Solr/Lucene index. We
    will need to index the documents again.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们将`termVectors=true`添加到我们的字段`author`和`*_t`（对于`series_t`）。术语向量是一组术语频率对，可选地包含位置信息。术语向量是Solr/Lucene索引的基本构建块。我们需要重新索引文档。
- en: Note
  id: totrans-43
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: For more information on how Lucene index works check out the documentation at
    [http://lucene.apache.org/core/4_5_1/core/org/apache/lucene/codecs/lucene45/package-summary.html](http://lucene.apache.org/core/4_5_1/core/org/apache/lucene/codecs/lucene45/package-summary.html)
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 有关Lucene索引工作原理的更多信息，请查看[http://lucene.apache.org/core/4_5_1/core/org/apache/lucene/codecs/lucene45/package-summary.html](http://lucene.apache.org/core/4_5_1/core/org/apache/lucene/codecs/lucene45/package-summary.html)
- en: 'In our PHP code, we will have to get the `MoreLikeThis` component from the
    query and add the fields on which we want to run this feature as shown in the
    following:'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的PHP代码中，我们将不得不从查询中获取`MoreLikeThis`组件，并添加我们想要运行此功能的字段，如下所示：
- en: '[PRE10]'
  id: totrans-46
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'This code says that we want to run the more like this similarity feature on
    fields'' `author` and `series_t`. This should work for fairly large data sets
    but let''s give it a few tweaks to make it run for our small books index using
    the following query:'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 此代码表示我们要在字段`author`和`series_t`上运行更多类似此相似功能。这对于相当大的数据集应该有效，但让我们进行一些调整，以使其适用于我们的小书籍索引，使用以下查询：
- en: '[PRE11]'
  id: totrans-48
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: This sets the minimum limits for classifying a document as a similar document.
    We will discuss more about these parameters in the 'tuning more like this query
    parameters' section.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 这设置了将文档分类为相似文档的最低限制。我们将在“调整更多类似此查询参数”部分讨论这些参数的更多信息。
- en: 'After running the query, we need to get the more like this component from the
    result set. And then while processing the documents in the result set, we need
    to get the similar documents from the more like this `resultset` component as
    shown in the following code:'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 运行查询后，我们需要从结果集中获取更多类似此组件。然后，在处理结果集中的文档时，我们需要从更多类似此`resultset`组件中获取相似的文档，如下所示的代码：
- en: '[PRE12]'
  id: totrans-51
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'Once we get the similar documents for a document, we can loop through the documents
    and get the details of similar documents. The following screenshot shows the output
    of this program:'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦我们为文档获取了类似的文档，我们可以循环遍历文档并获取类似文档的详细信息。以下屏幕截图显示了此程序的输出：
- en: '![Running more like this query using PHP](graphics/4920OS_08_03.jpg)'
  id: totrans-53
  prefs: []
  type: TYPE_IMG
  zh: '![使用PHP运行更多类似此查询](graphics/4920OS_08_03.jpg)'
- en: We can see in the Solr logs that the two main parameters that are passed to
    Solr are `mlt=true` & `mlt.fl=author,series_t`. To see the same result directly
    from Solr we can use the following query at `http://localhost:8080/solr/collection1/select/?mlt=true&rows=10&mlt.count=2&mlt.mindf=1&mlt.fl=author,series_t&fl=id,name,author,series_t,score,price&start=0&q=cat:book&mlt.mintf=1`.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以在Solr日志中看到传递给Solr的两个主要参数是`mlt=true`和`mlt.fl=author,series_t`。要直接从Solr中看到相同的结果，我们可以在`http://localhost:8080/solr/collection1/select/?mlt=true&rows=10&mlt.count=2&mlt.mindf=1&mlt.fl=author,series_t&fl=id,name,author,series_t,score,price&start=0&q=cat:book&mlt.mintf=1`使用以下查询。
- en: 'Here the parameters are explained as follows:'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 这里解释了以下参数：
- en: '**mlt.count**: This specifies the number of similar documents that we want
    to fetch for each document in the result set'
  id: totrans-56
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**mlt.count**：这指定我们要为结果集中的每个文档获取的相似文档的数量'
- en: '**mlt.mindf**: This is the minimum document frequency at which words will be
    ignored which do not occur in at least these many documents'
  id: totrans-57
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**mlt.mindf**：这是忽略词语的最小文档频率，这些词语在至少这么多文档中不出现'
- en: '**mlt.mintf**: This is the minimum term frequency after which terms will be
    ignored in the source document'
  id: totrans-58
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**mlt.mintf**：这是源文档中忽略术语的最小频率'
- en: More like this tuning parameters
  id: totrans-59
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 更多类似此调整参数
- en: 'Let us see some additional functionality that can be used to tune the more
    like this feature. We can use the following functions:'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看一些可以用来调整更多类似此功能的附加功能。我们可以使用以下功能：
- en: '**setMinimumDocumentFrequency()** and **setMinimumTermFrequency()**: These
    are to set the minimum document frequency and minimum term frequency that we saw
    earlier. If the variables are not set they are not passed to Solr and Solr uses
    the default parameters of `minimumDocumentFrequency` as `5` and `minimumTermFrequency`
    as `2`.'
  id: totrans-61
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**setMinimumDocumentFrequency()**和**setMinimumTermFrequency()**：这些是用于设置我们之前看到的最小文档频率和最小术语频率的方法。如果未设置变量，则它们不会传递给Solr，Solr将使用`minimumDocumentFrequency`的默认参数为`5`，`minimumTermFrequency`的默认参数为`2`。'
- en: '**setMinimumWordLength()**: This can be used to set the minimum word length
    below which words will be ignored.'
  id: totrans-62
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**setMinimumWordLength()**：可用于设置最小词长，低于该长度的单词将被忽略。'
- en: '**setMaximumWordLength()**: This can be used to set the maximum word length
    above which words will be ignored.'
  id: totrans-63
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**setMaximumWordLength()**：可用于设置最大词长，高于该长度的单词将被忽略。'
- en: '**setMaximumQueryTerms()**: This can be used to set the maximum number of query
    terms that will be included in any generated query. If it is not set it is not
    passed to Solr and in that case the default value of Solr which is 25 is applied.'
  id: totrans-64
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**setMaximumQueryTerms()**：可用于设置将包括在任何生成的查询中的最大查询项数。如果未设置，它将不会传递给Solr，在这种情况下，Solr的默认值为25。'
- en: '**setMaximumNumberOfTokens()**: This can be used to set the maximum number
    of tokens to parse in each doc field that is not stored with `TermVector` support.
    Default is 5000 which will be applied if we do not pass any parameter to Solr.'
  id: totrans-65
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**setMaximumNumberOfTokens()**：可用于设置每个未存储`TermVector`支持的文档字段中要解析的最大标记数。默认值为5000，如果不向Solr传递任何参数，则将应用该值。'
- en: '**setBoost()**: If `true` it boosts the query by the interesting term relevance.
    Default is `false`.'
  id: totrans-66
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**setBoost()**：如果为`true`，则通过有趣的术语相关性提升查询。默认值为`false`。'
- en: '**setCount()**: This can be used to set the `mlt.count` parameter in Solr.
    It specifies how many similar documents to fetch for each document in the result
    set.'
  id: totrans-67
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**setCount()**：可用于设置Solr中的`mlt.count`参数。它指定要为结果集中的每个文档获取多少相似文档。'
- en: '**setQueryFields()**: This can be used to specify the query fields and their
    boosts. These fields must also be set in `setFields()` function.'
  id: totrans-68
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**setQueryFields()**：可用于指定查询字段及其增强。这些字段也必须在`setFields()`函数中设置。'
- en: Distributed search
  id: totrans-69
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 分布式搜索
- en: When an index becomes too large to fit in a single machine, we can shard it
    and distribute it across multiple machines. Sharding requires a strategy that
    decides the shard to which a document is to be indexed based on certain values
    in certain fields. This strategy can be based on date, type of documents and so
    on. Though indexing has to happen separately for multiple shards, the search has
    to happen through a single interface. We should be able to specify the shards
    and the query should be run on all shards and return results for all shards. Solarium
    makes searching across multiple shards easy. Solarium supports distributed search
    through the `DistributedSearch` component. This allows us to query multiple shards
    using a single interface and get results from all shards.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 当索引变得太大而无法放入单台机器时，我们可以对其进行分片，并将其分布到多台机器上。分片需要一个策略，根据某些字段中的某些值决定要将文档索引到哪个分片。这个策略可以基于日期、文档类型等。虽然必须分别为多个分片进行索引，但搜索必须通过单个接口进行。我们应该能够指定分片，并且查询应该在所有分片上运行并返回所有分片的结果。Solarium使跨多个分片进行搜索变得容易。Solarium通过`DistributedSearch`组件支持分布式搜索。这允许我们使用单个接口查询多个分片，并从所有分片获取结果。
- en: Another way of scaling your search infrastructure is to create a master-slave
    Solr architecture. Master can be used to add documents in your index and slaves
    can be used to provide search. This architecture can help scale the search over
    a large number of servers. It is generally recommended to create an infrastructure
    that has both replicas and shards. The Solr cloud is a solution that provides
    such an infrastructure with easy management and monitoring.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 另一种扩展搜索基础架构的方法是创建主从Solr架构。主服务器用于向索引中添加文档，从服务器用于提供搜索。这种架构可以帮助在大量服务器上扩展搜索。通常建议创建既有副本又有分片的基础架构。Solr云是一个提供这样的基础架构的解决方案，具有易于管理和监控的特点。
- en: Setting up a distributed search
  id: totrans-72
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 设置分布式搜索
- en: Let us create a new Solr instance that we will use as a separate shard. Go to
    the directory where Solr is installed and create a copy of the `example` folder,
    `example2`. This creates a new instance of Solr where the index and schema are
    copied. Now start the Solr server inside the `example2` folder. We have a new
    Solr instance running on port 8983\. Our earlier instance is running on port 8080.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们创建一个新的Solr实例，作为一个独立的分片。转到安装Solr的目录，并创建`example`文件夹的副本，`example2`。这将创建一个新的Solr实例，其中包含复制的索引和模式。现在在`example2`文件夹中启动Solr服务器。我们在端口8983上运行一个新的Solr实例。我们之前的实例在端口8080上运行。
- en: Note
  id: totrans-74
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: 'The corresponding commands for Linux users are:'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: Linux用户的相应命令是：
- en: '[PRE13]'
  id: totrans-76
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: For Windows users, you can simply copy the `example` folder using Windows Explorer
    and then run `java-jar start.jar –Djetty.port=8983` in command prompt after `cd`
    to `example2` folder.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 对于Windows用户，您可以使用Windows资源管理器简单地复制`example`文件夹，然后在`example2`文件夹中`cd`后在命令提示符中运行`java-jar
    start.jar –Djetty.port=8983`。
- en: To kill an existing server press *Ctrl* + *C* on your command prompt where the
    Solr server is running.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 要终止现有服务器，请在运行Solr服务器的命令提示符上按下*Ctrl* + *C*。
- en: To check the Solr instance go to `http://localhost:8983/solr/`.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 要检查Solr实例，请转到`http://localhost:8983/solr/`。
- en: Since we have copied the index as well, the new instance of Solr will have all
    the documents that we had. Let us delete all the documents from the index and
    push some new documents to the index.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 由于我们已经复制了索引，新的Solr实例将包含我们之前的所有文档。让我们从索引中删除所有文档，并向索引中添加一些新文档。
- en: '`http://localhost:8983/solr/update?stream.body=<delete><query>*:*</query></delete>`'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: '`http://localhost:8983/solr/update?stream.body=<delete><query>*:*</query></delete>`'
- en: '`http://localhost:8983/solr/update?stream.body=<commit/>`'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: '`http://localhost:8983/solr/update?stream.body=<commit/>`'
- en: 'Add more books from the `books2.csv` file with the following command:'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 使用以下命令从`books2.csv`文件添加更多书籍：
- en: '[PRE14]'
  id: totrans-84
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: Executing a distributed search using PHP
  id: totrans-85
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用PHP执行分布式搜索
- en: 'To do a search on multiple shards, first we need to get the distributed search
    component from Solr. And then add shards to search as given in the following code:'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 要在多个分片上进行搜索，首先需要从Solr获取分布式搜索组件。然后按照以下代码添加分片进行搜索：
- en: '[PRE15]'
  id: totrans-87
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: After executing the search we get a result set that has results from both the
    shards and can use it as we have used result sets earlier.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 执行搜索后，我们会得到一个结果集，其中包含来自所有分片的结果，可以像之前使用结果集一样使用它。
- en: When we execute the search, we can see that Solr logs on both servers receive
    entries pertaining to this search. The parameters that are passed are `shard.url`
    (which contains the URL for Solr) and `isShard=true`.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们执行搜索时，我们可以看到两个服务器的Solr日志都接收到与此搜索相关的条目。传递的参数是`shard.url`（包含Solr的URL）和`isShard=true`。
- en: 'Instead of adding shard one after another, we can add multiple shards in a
    single go using the `addShards()` function as given in the following:'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以使用`addShards()`函数一次性添加多个分片，而不是一个接一个地添加分片，如下所示：
- en: '[PRE16]'
  id: totrans-91
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: Solr has come out with the Solr cloud. So instead of using shards, we can set
    up a Solr cloud where data is automatically sharded and we can get in touch with
    any Solr instance to get the results of our query.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: Solr推出了Solr云。因此，我们可以设置Solr云，而不是使用分片，其中数据会自动分片，并且我们可以与任何Solr实例联系以获取我们的查询结果。
- en: The Solr cloud has a concept of collections. So instead of adding cores, we
    will be required to add collections using the `addCollection()` or the `addCollections()`
    function. This functionality is available in Solarium 3.1 and higher.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: Solr云有一个集合的概念。因此，我们将需要使用`addCollection()`或`addCollections()`函数添加集合，而不是添加核心。此功能在Solarium
    3.1及更高版本中可用。
- en: Setting up Solr master-slave
  id: totrans-94
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 设置Solr主从复制
- en: 'We can set up Solr replication where the master Solr server is used for indexing
    and both master and slave Solr servers can be used for searches. Setting up replication
    is pretty simple in Solr. Check out the `requestHandler` named/`replication`.
    Simply create a copy of the `example` folder inside Solr as `example3` and empty
    the index files from the `example3` folder with the following command:'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以设置Solr复制，其中主Solr服务器用于索引，主服务器和从服务器都可以用于搜索。在Solr中设置复制非常简单。查看名为`replication`的`requestHandler`。只需将Solr中的`example`文件夹复制为`example3`，并使用以下命令从`example3`文件夹中清空索引文件：
- en: '[PRE17]'
  id: totrans-96
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'In the master server (`example` folder), change the `solrconfig.xml` file to
    add configuration parameters for the replication master with the following code:'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 在主服务器（`example`文件夹）中，更改`solrconfig.xml`文件以添加复制主服务器的配置参数，使用以下代码：
- en: '[PRE18]'
  id: totrans-98
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: Here, we have specified that replication should happen after a start up and
    after a commit on Solr. And the `schema.xml` and `stopwords.txt` files should
    be replicated.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们指定了复制应该在启动后和Solr提交后发生。`schema.xml`和`stopwords.txt`文件应该被复制。
- en: 'On `slave` Solr (`example3` folder), change the `solrconfig.xml` file to add
    slave Solr configuration parameters. The parameters to be specified are the master
    Solr server URL and the poll interval for checking Solr. Here the poll interval
    is defined as HH:MM:SS (hours:minutes:seconds) as illustrated in the following
    code:'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 在`slave` Solr（`example3`文件夹）中，更改`solrconfig.xml`文件以添加从Solr配置参数。需要指定的参数是主Solr服务器的URL和检查Solr的轮询间隔。这里的轮询间隔定义为HH:MM:SS（小时:分钟:秒），如下所示的代码：
- en: '[PRE19]'
  id: totrans-101
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'Restart Tomcat and start up the Solr server in `example3` folder using the
    `java –jar start.jar` command we have used earlier. This will start Solr on port
    8983\. This Solr server will act as the slave and poll the master for updates.
    All the index files are replicated on the slave Solr as shown in the following
    screenshot:'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 重新启动Tomcat，并使用我们之前使用的`java –jar start.jar`命令在`example3`文件夹中启动Solr服务器。这将在端口8983上启动Solr。这个Solr服务器将充当从服务器，并轮询主服务器进行更新。所有索引文件都会在从服务器上复制，如下截图所示：
- en: '![Setting up Solr master-slave](graphics/4920OS_08_04.jpg)'
  id: totrans-103
  prefs: []
  type: TYPE_IMG
  zh: '![设置Solr主从复制](graphics/4920OS_08_04.jpg)'
- en: Solr interface for master server.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 主服务器的Solr界面。
- en: 'In the Solr interface for the master server as shown in the preceding screenshot,
    we can see that it is defined as the replication master with a version number
    for the index. In the Solr slave server as shown in the following, we can see
    that there is a slave and reference to master. Note that the version numbers are
    matching in the screenshot:'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的截图中，我们可以看到主服务器的Solr界面中定义了复制主服务器，并带有索引的版本号。在下面的从服务器的Solr界面中，我们可以看到有一个从服务器和对主服务器的引用。请注意，截图中的版本号是匹配的：
- en: '![Setting up Solr master-slave](graphics/4920OS_08_05.jpg)'
  id: totrans-106
  prefs: []
  type: TYPE_IMG
  zh: '![设置Solr主从复制](graphics/4920OS_08_05.jpg)'
- en: Solr interface for slave server.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 从服务器的Solr界面。
- en: Load balancing Solr queries using PHP
  id: totrans-108
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用PHP进行Solr查询的负载均衡
- en: 'Solarium comes with a load balancer plugin that can be used to build redundancy
    among multiple Solr servers. The load balancer plugin has the following features:'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: Solarium带有一个负载均衡器插件，可用于在多个Solr服务器之间建立冗余。负载均衡器插件具有以下功能：
- en: Support for multiple servers, each with their own weight.
  id: totrans-110
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 支持多个服务器，每个服务器都有自己的权重。
- en: The ability to use a failover mode—try another Solr server if a query fails.
  id: totrans-111
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用故障转移模式的能力——如果查询失败，则尝试另一个Solr服务器。
- en: Block certain query types. Updates are by default blocked.
  id: totrans-112
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 阻止某些查询类型。更新默认被阻止。
- en: Force a specific server for the next query.
  id: totrans-113
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 强制下一个查询使用特定服务器。
- en: 'Add all Solr servers where you want to distribute your queries to your Solarium
    client configuration. In our case, we will be adding the master and slave Solr
    servers that we have recently set up with the following code:'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 将要分发查询的所有Solr服务器添加到您的Solarium客户端配置中。在我们的情况下，我们将使用以下代码添加最近设置的主服务器和从服务器：
- en: '[PRE20]'
  id: totrans-115
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'Next, we need to create the endpoints from the Solarium client, get the load
    balancer plugin from the client and add the endpoints to the load balancer with
    respective weights as shown in the following code:'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们需要从Solarium客户端创建端点，从客户端获取负载均衡器插件，并将端点添加到负载均衡器中，并显示相应的权重，如下所示的代码：
- en: '[PRE21]'
  id: totrans-117
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'Enable failover to another Solr server after query fails on any server. Limit
    maximum number of retries to 2 before declaring the Solr server as unreachable
    and failing over to another server with the following queries:'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 在任何服务器上的查询失败后，启用故障转移到另一个Solr服务器。在将Solr服务器声明为不可达并故障转移到另一个服务器之前，将最大重试次数限制为2次，使用以下查询：
- en: '[PRE22]'
  id: totrans-119
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'Here we have set the weight of master server as `1` and slave server as `5`.
    So on average 1 out of 6 queries will go to the master. If we want to force a
    query on the master, we can use the `setForcedEndpointForNextQuery()` function
    as shown in the following query:'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们将主服务器的权重设置为`1`，从服务器的权重设置为`5`。因此，平均每6个查询中就有1个会发送到主服务器。如果我们想要强制查询主服务器，我们可以使用`setForcedEndpointForNextQuery()`函数，如下面的查询所示：
- en: '[PRE23]'
  id: totrans-121
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: Summary
  id: totrans-122
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: In this chapter, we discussed some of the advanced functionalities available
    in Solr and the Solarium library. We saw grouping of results based on field and
    query. And we also saw a functionality known as more like this, which can be used
    to extract results similar to a particular document from Solr based on some fields
    of the original document. We saw how to scale Solr beyond a single machine using
    replication and sharding. And we saw the functionalities provided by Solarium
    for scaling Solr.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们讨论了Solr和Solarium库中可用的一些高级功能。我们看到了基于字段和查询的结果分组。我们还看到了一个称为更多类似的功能，它可以根据原始文档的一些字段从Solr中提取类似于特定文档的结果。我们看到了如何使用复制和分片将Solr扩展到单个机器之外。我们还看到了Solarium为扩展Solr提供的功能。
